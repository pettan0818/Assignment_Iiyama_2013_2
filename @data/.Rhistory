#help(Glass)
data(Glass); G=Glass[,c(1:5,10)]
m1=NaiveBayes(Type~. ,data=G)
m1.p=predict(ml)
tem1=table(G$Type, m1.p$class)
print(1-sum(diag(tem1))/sum(tem1))
data(Glass); G=Glass[,c(1:5,10)]
m1=NaiveBayes(Type~. ,data=G)
m1.p=predict(m1)
tem1=table(G$Type, m1.p$class)
print(1-sum(diag(tem1))/sum(tem1))
m1
plot(m2)
m2=NaiveBayes(Type~.,data=G,usekernel=T)
m2.p=predict(m2)
tem2=table(G$Type,m2.p$class)
#ErrorRate
print(1-sum(diag(tem1))/sum(tem1))
plot(m2)
plot(m1)
q()
library(survival)
library(survival);library(MASS)
data(gehan);dim(gehan)
head(gehan)
Surv(gehan$time,gehan$cens)
genah_suv=Surv(gehan$time,gehan$cens)
plot(gehan_suv)
gehan_suv=Surv(gehan$time,gehan$cens)
plot(gehan_suv)
barplot(gehan_suv)
ge.sf=survfit(Surv(time,cens)~treat,data=gehan)
ge.sf
summary(ge.sf)
plot(ge.sf,lty=1:2)
help(legend)
legend(locator(50,50),c("6-MP投与群","対照群"),lty=c(1,2))
kidney.cox=coxph(Surv(time, status)~sex+disease, data=kidney)
kidney.fit=survfit(kidney.cox)
knitr
library(knitr)
help(knitr)
install.packages("ggplot")
install.packages("ggplot2")
library(ggplot2)
data0~iris
data0=iris
data0
plot(data0)
ggplot(data0)
ggplot(data0,aes(x=data0[,1],y=data0[,2]))
p=ggplot(data0,aes(x=data0[,1],y=data0[,2]))
p + deom_poin()
p + geom_poin()
p + geom_point()
p=ggplot(data0)
p + geom_point()
p=ggplot(data0,aes(x=Sepal.Width,y=Sepal.Width))
p + geom_point()
p=ggplot(data0,aes(x=Sepal.Width,y=Sepal.Length))
p + geom_point()
p=ggplot(data0,aes(x=Sepal.Width,y=Sepal.Length,colour=Species))
p + geom_point()
-7.938e-09
-7.938e-09*1000000
-1.181e-04
q()
lh
plot(lh)
print(UKgas)
plot(UKGus)
plot(UKgas)
print(UKgas)
mdeath
print(mdeaths)
print(ldeaths)
plot(mdeaths)
plot(ldeaths)
plot(diff(UKgas))
d_UKgas=diff(UKgas)
acf(d_UKgas)
d_lh=diff(lh)
acf(d_lh)
op=par(mfrow=c(2,2),mar=c(5,4,4,2))
sepec.pgram(UKgas)
sepc.pgram(UKgas)
spec.pgram(UKgas)
spec.pgram(UKgas,spans=c(3,3))
spec.pgram(UKgas)
spec.pgram(ldeaths)
spec.pgram(UKgas)
spec.pgram(UKgas,spans=c(3,3))
par(op)
spec.pgram(UKgas)
spec.pgram(ldeaths.spans=c(3.3))
spec.pgram(ldeaths,spans=c(3.3))
spec.pgram(diff(UKgas))
spec.pgram(UKgas)
spec.pgram(diff(UKgas))
spec.pgram(UKgas)
spec.pgram(diff(UKgas))
spec.pgram(UKgas,spans=c(3,3))
lh.ar=ar(lh)
print(lh.ar)
summary(lh.ar)
lh.pr=predict(lh.ar,n.ahead=10)
print(lh.pr)
library(randomForest)
partialPlot
help(partialPlot)
data(iris)
data
data()
set.seed(555)
iris.rf=randomForest(Species~., iris)
partialPlot(iris.rf)
partialPlot(iris.rf,iris,Petal.Width, "versicolor")
data(airquality)
airquality <- na.omit(airquality)
set.seed(131)
ozone.rf <- randomForest(Ozone ~ ., airquality, importance=TRUE)
imp <- importance(ozone.rf)
impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
op <- par(mfrow=c(2, 3))
for (i in seq_along(impvar)) {
partialPlot(ozone.rf, airquality, impvar[i], xlab=impvar[i],
main=paste("Partial Dependence on", impvar[i]),
ylim=c(30, 70))
}
par(op)
library(car)
library("car")
install.packages("car")
library(car)
car
help(car)
data(iris)
data(car)
data(swiss)
importIntoEnv
install.packages("python")
98*800
req(800)
seq(800)
800^2
sqrt()
sqrt(100000)
sqrt(1000)
sqrt(100)
sqrt(1000000)
sqrt(1000000,3)
help(squr)
help(squt)
help(sqrt)
require(stats)
stats
require(math)
install.packages("math")
exit
quit()
library(plm)
install.package("kintr")
install.packages("kintr")
install.packages("knitr")
r=10
rarara=10
I(rarara^2)
I()
wdi_plm=plm.data(data,c("cid","year"))
library(knitr)
lh.ari=arima(lh,order=c(2,0,1))
(lh.ari=arima(lh,order=c(2,0,1)))
library(rpart)
library(mvpart)
install.packages("mvpart")
iris.rp=rpart(Species.~,data-iris)
iris.rp=rpart(Species.~,data=iris)
iris.rp=rpart(Species~.,data=iris)
print(iris.rp,digit=1)
plot(iris.rp,uniform=T,branch=0.6,margin=0.05)
text(iris.rp,use.n=7,all=T)
iris.rp=mvpart(Species~.,data=iris)
libarary(mvpart)
library(mvpart)
iris.rp=mvpart(Species~.,data=iris)
print(iris.rp,digit=1)
plot(iris.rp,uniform=T,branch=0.6,margin=0.05)
text(iris.rp,use.n=7,all=T)
```
iris.rp=mvpart(Species~.,data=iris)
library(MASS)
pima.rp=mvpart(type~.,data=Pima.te)
print(pima.rp)
plot(pima.rp,uniform=T,branch=0.6,margin=0.5)
text(pima.rp,use.n=T,all=T)
pima.pred=predict(pima.rp,Pima[1:7])
pima.pred=predict(pima.rp,Pima.tr[1:7])
summary(pima.pred)
table(Pima.tr[,8],pima.pred)
pima.pred=predict(pima.rp,Pima.tr[1:7],type='class)
pima.pred=predict(pima.rp,Pima.tr[1:7],type='class')
table(Pima.tr[,8],pima.pred)
(pima.pred=predict(pima.rp,Pima.tr[1:7]))
help(mvpart)
q()
View(seto.var)
help(is.na)
T && F
F && F
T && T
library(tseries)
install.packages("tseries")
irts
library(MASS)
print(Pima.te)
library(nnet)
plot(iris)
even.n=2*(1:75)
iris.train=iris[even.n,]
iris.train=iris[-even.n,]
#ニューラルネットワークによる学習
iris.nnet=nnet(Species~.,seize=3,decay=0.1,data=iris.train)
iris.nnetp=predict(iris.nnet,iris.test[,-5],type="class")
iris.nnet=nnet(Species~.,size=3,decay=0.1,data=iris.train)
iris.nnetp=predict(iris.nnet,iris.test[,-5],type="class")
(iris.nnet=nnet(Species~.,size=3,decay=0.1,data=iris.train))
(iris.nnetp=predict(iris.nnet,iris.test[,-5],type="class"))
table(iris.test[,5],iris.nnetp)
pima.te
library(MASS)
pima.te
pima.knn
head(Pima.te)
(Pima.nnet=nnet(type~.,size=3,decay=0.1,data=Pima.te))
(Pima.nnetp=predict(iris.nnet,Pima.tr,type="class"))
(Pima.nnetp=predict(Pima.nnet,Pima.tr,type="class"))
table(iris.test[,5],iris.nnetp)
head(Pima.tr)
(Pima.nnetp=predict(Pima.nnet,Pima.tr[,-8],type="class"))
table(Pima.tr[,8],Pima.nnetp)
(Pima.nnet=nnet(type~.,size=3,decay=0.1,data=Pima.te))
(Pima.nnetp=predict(Pima.nnet,Pima.tr[,-8],type="class"))
table(Pima.tr[,8],Pima.nnetp)
(Pima.nnet=nnet(type~.,size=5,decay=0.1,data=Pima.te))
(Pima.nnetp=predict(Pima.nnet,Pima.tr[,-8],type="class"))
table(Pima.tr[,8],Pima.nnetp)
(Pima.nnet=nnet(type~.,size=25,decay=0.1,data=Pima.te))
(Pima.nnetp=predict(Pima.nnet,Pima.tr[,-8],type="class"))
table(Pima.tr[,8],Pima.nnetp)
(Pima.nnet=nnet(type~.,size=1000,decay=0.1,data=Pima.te))
(Pima.nnet=nnet(type~.,size=8500,decay=0.1,data=Pima.te))
tan()
tan(30)
tan(45)
install=try(library(kernlab))
if(class(install)=="try-error"){
options(repos = "http://cran.r-project.org/")
install.packages("kernlab")
library(kernlab)
}
data(spam)
dim(spam)
table(spam[,58])
(spam.svm=ksvm(type.~,data=spam.train,cross=3))
(spam.svm=ksvm(type~.,data=spam.train,cross=3))
data(spam)
dim(spam)
table(spam[,58])
# 学習用データと確認用データを切り分ける
set.seed(50)
tr.num=sample(4601,2500)
spam.train=spam[tr.num]
spam.test=spam[-tr.num]
set.seed(50)
(spam.svm=ksvm(type~.,data=spam.train,cross=3))
tr.num=sample(4601,2500)
spam.train=spam[tr.num,]
spam.test=spam[-tr.num,]
set.seed(50)
(spam.svm=ksvm(type~.,data=spam.train,cross=3))
(spam.pre=predict(spam.svm,spam,test[,-68]))
(spam.pre=predict(spam.svm,spam.test[,-68]))
(spam.tab=table(spam.test[,58],spam.pre))
1-sum(diag(spam.tab))/sum(spam.tab)
library(nnet)
nnet.res=nnet(type~., data=spam.train)
nnet.pre=predict(nnet.res,spam.test[,-58],type="class")
nnet.res=nnet(type~., data=spam.train, size=3)
nnet.pre=predict(nnet.res,spam.test[,-58],type="class")
summary(nnet.pre)
table(spam.test[58],nnet.pre)
y=as.matrix(iris[51:150,5])
iris1=data.frame(iris[51:150,3:4],y)
set.seed(0)
iris.ksvm(y~.,data=iris1[,1:2])
table(iris1$y,predict(ir.ksvm,iris1[,1:2]))
y=as.matrix(iris[51:150,5])
iris1=data.frame(iris[51:150,3:4],y)
set.seed(0)
iris.ksvm=ksvm(y~.,data=iris1[,1:2])
table(iris1$y,predict(ir.ksvm,iris1[,1:2]))
table(iris1$y,predict(iris.ksvm,iris1[,1:2]))
plot(iris.ksvm,data=iris1[,1:2])
quit()
library(ggplot2)
data=iris
data
ggplot(data)
ggplot(data,aes(x=colnames(iris[,2],y=colnames(iris[,3]))))
p + geom_point()
geom_point()
library(ggplot2)
data0<-iris
ggplot(data0,
aes(x=Sepal.Length,
y=Sepal.Width
)
p + geom_point()
library(ggplot2)
data0<-iris
p=ggplot(data0,
aes(x=Sepal.Length,
y=Sepal.Width
)
p + geom_point()
p=ggplot(data,aes(x=colnames(iris[,2],y=colnames(iris[,3]))))
p + geom_point()
names
name
names(iris[,2])
names(iris[2,])
names(iris[2,][2])
names(iris[2])
p=ggplot(data,aes(x=names(iris[2],y=names(iris[3]))))
p + geom_point()
p=ggplot(data,aes(x=names(iris[2]),y=names(iris[3]))))
p=ggplot(data,aes(x=names(iris[2]),y=names(iris[3])))
p + geom_point()
p=ggplot(data,aes(x="Sepal.Width",y="Sepal.Length"))
p + geom_point()
data
p=ggplot(data,aes(x=Sepal.Width,y=Sepal.Length))
data
p + geom_point()
p=ggplot(data,aes(x=Sepal.Width,y=Sepal.Length,shape=Speceis))
p + geom_point()
p=ggplot(data,aes(x=Sepal.Width,y=Sepal.Length,shape=Species))
p + geom_point()
p=ggplot(data,aes(x=Sepal.Width,y=Sepal.Length,colour=Species,shape=Species))
p + geom_point()
p + geom_point(size=5)
p + geom_point(size=3)
p + geom_point(size=3,alpha=0.75)
p + geom_point(size=3,alpha=0.5)
p + geom_point(size=3,alpha=0.25)
p + geom_point(size=13,alpha=0.25)
car
data
rm(data)
data
data()
CO2
rock
help(ggplot)
example(ggplot)
namespaceExport(ggplot2)
ggplot2
help(package="ggplot2")
example(geom_title)
example(geom_tile)
example(geom_violin)
example(geom_polygon)
help(aes)
attach(data)
head(iris)
p=ggplot(data,aes(x=Sepal.Length,y=Sepal.Width),colour=Species)
p=ggplot(data,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
p
summary(p)
p=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
data1=iris
data2=rock
p=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
attach(data1)
p=ggplot(data,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
detach()
p=ggplot(data,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
p=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
attach(data1)
p=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
plot_data1=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
install=try(library(ggplot2))
plot_data1=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species))
plot_data1 + geom_point()
attach(data1)
plot_data1=ggplot(data1,aes(x=Sepal.Length,y=Sepal.Width,colour=Species,shape=Species,fill=Species))
plot_data1 + geom_point()
plot_data1 + geom_point(alpha=0.5,size=3)
help(geom_point)
help(example)
example(geom_point,ask=F)
mtcars
help(factor)
factor(data1[Sepal.Length])
data1[Sepal.Length]
data1[3]
factor(data1[3])
factor(data1[5])
attach(data1)
plot_data1 + geom_point(aes(colour = Sepal.Width)) + scale_colour_gradient(low="blue")
plot_data1 + geom_point(aes(colour = Sepal.Width)) + scale_size_area()
plot_data1 + geom_point(aes(size = Sepal.Width)) + scale_size_area()
plot_data1 + geom_point(aes(size = Sepal.Width,alpha=0.25)) + scale_size_area()
plot_data1 + geom_point(aes(size = Sepal.Width,alpha=0.1)) + scale_size_area()
plot_data1 + geom_point(aes(size = Sepal.Width),alpha=0.1) + scale_size_area()
plot_data1 + geom_point(aes(size = Sepal.Width),alpha=0.75) + scale_size_area()
plot_data1 + geom_point(alpha=0.5,size=3)
plot_data1 + geom_point(aes(colour = Sepal.Width)) + scale_colour_gradient(low="blue")
p+geom_histogram
plot_data1+ geom_histogram()
plot_data1+ geom_bar()
help(geom_hist)
help(geom_histogram)
example(geom_histogram,ask=F)
quit()
library(mlbench)
data(BreastCancer)
summary(BreastCancer)
head(BreastCancer)
even.n=2*(1:349)
BC.train=BreastCancer[even.n,-1]
BC.test=BreastCancer[-even.n,-1]
install.packages("adabag");library(adabag)
install.packages("adabag")
install.packages("svm")
BC.ba=bagging(Class~ .,data=BC.train)
BC.bap=predict(BC.ba,BC.test)
(ta.ba=table(BC.test)[,10],BC.bap$class)
(ta.ba=table(BC.test[,10],BC.bap$class)
)
1-sum(diag(tb.ba))/sum(tb.ba)
(tb.ba=table(BC.test[,10],BC.bap$class))
1-sum(diag(tb.ba))/sum(tb.ba)
BC.ba=bagging(Class~ .,data=BC.train)
BC.bap=predict(BC.ba,BC.test)
(tb.ba=table(BC.test[,10],BC.bap$class))
1-sum(diag(tb.ba))/sum(tb.ba)
BC.ba=bagging(Class~ .,data=BC.train)
BC.bap=predict(BC.ba,BC.test)
(tb.ba=table(BC.test[,10],BC.bap$class))
1-sum(diag(tb.ba))/sum(tb.ba)
BC.ba=bagging(Class~ .,data=BC.train)
BC.bap=predict(BC.ba,BC.test)
(tb.ba=table(BC.test[,10],BC.bap$class))
1-sum(diag(tb.ba))/sum(tb.ba)
set.seed(20)
BC.rp=rpart(Class~.,data=BD.train,maxdepth=3)
BC.rpp=predict(BC.rp,newdata=BC.test[,10],type="class")
(tb.rp=table(BC.rpp,BC.test[10]))
BC.rp=rpart(Class~.,data=BC.train,maxdepth=3)
BC.rpp=predict(BC.rp,newdata=BC.test[,10],type="class")
BC.rpp=predict(BC.rp,newdata=BC.test[,-10],type="class")
(tb.rp=table(BC.rpp,BC.test[10]))
(tb.rp=table(BC.rpp,BC.test[,10]))
1-sum(diag(tb.rp))/sum(tb.rp)
BC.ad=adaboost.M1(Class~.,data=BC.train)
BC.ad=adaboost.Ml(Class~.,data=BC.train)
BC.ad=adaboost.MI(Class~.,data=BC.train)
je
help(package=adabag)
BC.ad=boosting(Class~.,data=BC.train)
BC.adp=predict(BC.ad,newdata=BC.test)
plot(BC.ad)
plot(BC.adp)
summary(BC.ad)
BC.adp=predict(BC.ad,newdata=BC.test)
BC.adp[-1]
install.packages("randomForest");library(randomForest)
set.seed(20)
BC.rf=randomForest(Class~.,data=BC.train,na.action="na.omit")
print(BC.rf)
plot(BC.rf)
varImpPlot(BC.rf)
BC.rfp=predict(BC.rf,data=BC.test[,-10])
(BC.rft=table(BC.test[,10],BC.rfp))
BC.completetest=complete.cases(BC.test)
BC.completetest
install.packages("arules",dependencies=T)
library(arules)
data(Groceries)
summary(Groceries)
itemFrequencyPlot(Groceries)
itemFrequencyPlot(Groceries[,1:55])
itemFrequencyPlot(Groceries[,1:25])
par(mfrow=c(1,3),mar=c(4.5,2,1,2),cex=0.65,cex.axis=0.7)
itemFrequencyPlot(Groceries[,1:55],cex=0.65,col="lightblue",horiz=T])
itemFrequencyPlot(Groceries[,1:55],cex=0.65,col="lightblue",horiz=T)
Gr.ap=apriori(Groceries, parameter=list(support=0.005,confidence=0.01))
beefRules = subset(Gr.ap,subset= rhs %in% "beef")
inspect(head(SORT(beefRules, by = "confidence"),n=3))
sodaRules = subset(Gr.ap,subset= rhs %in% "soda")
inspect(head(SORT(sodaRules, by = "confidence"),n=3))
getwd()
setwd("C:/Users/Noname/Desktop/sushi3/")
read.delim("sushi3.idata")
read.delim("sushi3.idata",sep=\t)
read.delim("sushi3.idata",sep="\t")
read.delim("sushi3.udata")
head(read.delim("sushi3.udata"))
summary(read.delim("sushi3.udata"))
quit
quit()
